# Plano de Otimiza√ß√£o de Performance - Dashboard eShows

## üìä An√°lise Executiva

Este documento apresenta um plano abrangente para otimizar a performance do Dashboard eShows, com foco em reduzir tempo de carregamento, melhorar responsividade e otimizar uso de recursos.

### M√©tricas Atuais
- **Tempo de carregamento inicial**: ~15-20 segundos
- **Uso de mem√≥ria**: ~400-500MB
- **Tempo de resposta callbacks**: 2-5 segundos
- **Cache hit rate**: ~30% (sub√≥timo)

### Metas de Performance
- **Tempo de carregamento**: < 5 segundos
- **Uso de mem√≥ria**: < 300MB
- **Tempo de resposta**: < 1 segundo
- **Cache hit rate**: > 80%

---

## üîç Problemas Identificados

### 1. Sistema de Cache Fragmentado

#### Problema
- **3 n√≠veis de cache** n√£o coordenados (RAM, Parquet, modulobase)
- Cache duplicado causando uso excessivo de mem√≥ria
- Falta de invalida√ß√£o coordenada

#### Impacto
- Uso de mem√≥ria 2x maior que necess√°rio
- Inconsist√™ncias entre caches
- Complexidade desnecess√°ria

#### Arquivos Afetados
- `app/data/data_manager.py`
- `app/data/modulobase.py`
- `app/core/main.py`

### 2. Carregamento Excessivo de Dados

#### Problema
- DataFrames globais carregados no in√≠cio (`utils.py`)
- Todos os dados carregados mesmo quando n√£o necess√°rios
- Falta de lazy loading

#### Impacto
- Tempo de inicializa√ß√£o lento
- Mem√≥ria desperdi√ßada com dados n√£o utilizados

#### Arquivos Afetados
- `app/utils/utils.py` (linhas 39-48)
- `app/core/main.py`

### 3. Processamentos Redundantes

#### Problema
- M√∫ltiplas convers√µes de tipo nas mesmas colunas
- Filtros de per√≠odo aplicados repetidamente
- C√°lculos duplicados de KPIs

#### Impacto
- CPU desperdi√ßada em reprocessamento
- Tempo de resposta lento em callbacks

#### Arquivos Afetados
- `app/kpis/variacoes.py`
- `app/core/main.py` (callback `atualizar_kpis`)

### 4. Consultas Ineficientes ao Banco

#### Problema
- Pagina√ß√£o sem √≠ndices otimizados
- Fetch de todos os dados + filtro em Python
- Queries n√£o otimizadas para o caso de uso

#### Impacto
- M√∫ltiplas requisi√ß√µes desnecess√°rias
- Transfer√™ncia excessiva de dados
- Lat√™ncia aumentada

#### Arquivos Afetados
- `app/data/data_manager.py` (fun√ß√£o `_fetch`)

### 5. Callbacks Monol√≠ticos

#### Problema
- Callback principal calcula TODOS os KPIs de uma vez
- Falta de granularidade nas atualiza√ß√µes
- Sem processamento ass√≠ncrono

#### Impacto
- Interface travada durante c√°lculos
- Usu√°rio espera mesmo por KPIs n√£o vis√≠veis

#### Arquivos Afetados
- `app/core/main.py` (linhas 2053-2499)

---

## üí° Solu√ß√µes Propostas

### Fase 1: Quick Wins (1-2 semanas)

#### 1.1 Implementar Cache Unificado
```python
# Criar classe UnifiedCache em app/utils/cache.py
class UnifiedCache:
    def __init__(self, ttl_hours=12):
        self._cache = {}
        self._timestamps = {}
        self.ttl = timedelta(hours=ttl_hours)
    
    def get(self, key, loader_func):
        if key in self._cache and self._is_fresh(key):
            return self._cache[key]
        
        data = loader_func()
        self._cache[key] = data
        self._timestamps[key] = datetime.now()
        return data
    
    def invalidate(self, pattern=None):
        # Invalidar cache por padr√£o
        pass
```

**Benef√≠cio**: Redu√ß√£o de 50% no uso de mem√≥ria

#### 1.2 Otimizar Tipos de Dados
```python
def optimize_dataframe_types(df):
    """Reduz uso de mem√≥ria em 60-70%"""
    for col in df.columns:
        col_type = df[col].dtype
        
        if col_type != 'object':
            c_min = df[col].min()
            c_max = df[col].max()
            
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
    
    return df
```

**Benef√≠cio**: Redu√ß√£o de 60% no uso de mem√≥ria dos DataFrames

#### 1.3 Implementar Memoiza√ß√£o
```python
from functools import lru_cache

@lru_cache(maxsize=128)
def calculate_kpi_cached(kpi_name, period, year):
    # C√°lculo do KPI
    pass
```

**Benef√≠cio**: 80% menos rec√°lculos

### Fase 2: Otimiza√ß√µes Estruturais (2-4 semanas)

#### 2.1 Lazy Loading de Dados
```python
class LazyDataManager:
    def __init__(self):
        self._data = {}
        self._loaders = {
            'baseeshows': self._load_baseeshows,
            'base2': self._load_base2,
            # etc
        }
    
    def get(self, dataset_name):
        if dataset_name not in self._data:
            self._data[dataset_name] = self._loaders[dataset_name]()
        return self._data[dataset_name]
```

**Benef√≠cio**: Carregamento 3x mais r√°pido

#### 2.2 Callbacks Granulares
```python
# Dividir callback grande em v√°rios menores
@app.callback(
    Output('kpi-gmv-col', 'children'),
    Input('dashboard-ano-dropdown', 'value'),
    prevent_initial_call=True
)
def update_gmv_only(ano):
    # Calcular apenas GMV
    pass

@app.callback(
    Output('kpi-nrr-col', 'children'),
    Input('dashboard-ano-dropdown', 'value'),
    prevent_initial_call=True
)
def update_nrr_only(ano):
    # Calcular apenas NRR
    pass
```

**Benef√≠cio**: Interface 5x mais responsiva

#### 2.3 Otimiza√ß√£o de Queries
```python
def fetch_optimized(table: str, filters: dict = None):
    query = supa.table(table).select("*")
    
    # Aplicar filtros no banco
    if filters:
        for key, value in filters.items():
            if isinstance(value, tuple):
                query = query.gte(key, value[0]).lte(key, value[1])
            else:
                query = query.eq(key, value)
    
    # Limitar colunas retornadas
    if table == "baseeshows":
        query = query.select("Id do Show,Data,Valor Total do Show,Id_da_Casa")
    
    return query.execute()
```

**Benef√≠cio**: 70% menos dados transferidos

### Fase 3: Otimiza√ß√µes Avan√ßadas (4-6 semanas)

#### 3.1 Implementar Data Streaming
```python
def stream_large_datasets(table_name, chunk_size=5000):
    """Processa dados em chunks para economizar mem√≥ria"""
    offset = 0
    
    while True:
        chunk = fetch_chunk(table_name, offset, chunk_size)
        
        if chunk.empty:
            break
            
        # Processar chunk
        yield process_chunk(chunk)
        
        offset += chunk_size
```

**Benef√≠cio**: Suporte para datasets 10x maiores

#### 3.2 Background Processing
```python
from dash.long_callback import DiskcacheLongCallbackManager
import diskcache

cache = diskcache.Cache("./cache")
long_callback_manager = DiskcacheLongCallbackManager(cache)

@app.long_callback(
    Output('kpi-results', 'data'),
    Input('calculate-btn', 'n_clicks'),
    manager=long_callback_manager,
    progress=[Output("progress", "value"), Output("progress", "max")]
)
def calculate_kpis_background(n_clicks):
    # Processamento pesado em background
    pass
```

**Benef√≠cio**: Interface nunca trava

#### 3.3 √çndices no Banco de Dados
```sql
-- Criar √≠ndices para queries comuns
CREATE INDEX idx_baseeshows_data ON baseeshows(Data);
CREATE INDEX idx_baseeshows_casa ON baseeshows("Id_da_Casa");
CREATE INDEX idx_base2_competencia ON base2(Ano, Mes);
CREATE INDEX idx_base2_tipo ON base2("Tipo de receita");

-- √çndice composto para filtros combinados
CREATE INDEX idx_baseeshows_data_casa ON baseeshows(Data, "Id_da_Casa");
```

**Benef√≠cio**: Queries 10x mais r√°pidas

---

## üìà Implementa√ß√£o e Monitoramento

### Cronograma

| Fase | Dura√ß√£o | Impacto Esperado |
|------|---------|------------------|
| Fase 1 | 1-2 semanas | 50% melhoria |
| Fase 2 | 2-4 semanas | 80% melhoria |
| Fase 3 | 4-6 semanas | 95% melhoria |

### M√©tricas de Acompanhamento

#### 1. Performance Profiling
```python
import cProfile
import pstats

def profile_app():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # Executar opera√ß√µes
    
    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)
```

#### 2. Monitoramento de Mem√≥ria
```python
import tracemalloc

tracemalloc.start()

# C√≥digo

current, peak = tracemalloc.get_traced_memory()
print(f"Current memory usage: {current / 10**6:.1f} MB")
print(f"Peak memory usage: {peak / 10**6:.1f} MB")
```

#### 3. Dashboard de Performance
```python
# Adicionar p√°gina de m√©tricas ao dashboard
@app.callback(
    Output('performance-metrics', 'children'),
    Input('interval-component', 'n_intervals')
)
def update_metrics(n):
    return html.Div([
        html.H4("Performance Metrics"),
        html.P(f"Cache Hit Rate: {cache.hit_rate:.1%}"),
        html.P(f"Avg Response Time: {avg_response_time:.2f}s"),
        html.P(f"Memory Usage: {get_memory_usage():.1f} MB")
    ])
```

### Testes de Performance

#### 1. Teste de Carga
```python
import concurrent.futures
import time

def load_test(num_users=10):
    def simulate_user():
        start = time.time()
        # Simular intera√ß√µes do usu√°rio
        return time.time() - start
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=num_users) as executor:
        futures = [executor.submit(simulate_user) for _ in range(num_users)]
        results = [f.result() for f in futures]
    
    print(f"Avg response time: {sum(results)/len(results):.2f}s")
```

#### 2. Benchmark de Queries
```python
def benchmark_queries():
    queries = [
        ("baseeshows", {}),
        ("baseeshows", {"Data": ("2024-01-01", "2024-12-31")}),
        ("base2", {"Ano": 2024})
    ]
    
    for table, filters in queries:
        start = time.time()
        data = fetch_optimized(table, filters)
        duration = time.time() - start
        print(f"{table} with {filters}: {duration:.2f}s ({len(data)} rows)")
```

---

## üéØ Resultados Esperados

### Performance
- **Tempo de carregamento**: 15s ‚Üí 3s (80% redu√ß√£o)
- **Tempo de resposta**: 3s ‚Üí 0.5s (83% redu√ß√£o)
- **Uso de mem√≥ria**: 450MB ‚Üí 200MB (55% redu√ß√£o)

### Experi√™ncia do Usu√°rio
- Interface mais fluida e responsiva
- Sem travamentos durante c√°lculos
- Feedback visual de progresso

### Escalabilidade
- Suporte para 10x mais dados
- Capacidade para 50+ usu√°rios simult√¢neos
- Preparado para crescimento futuro

---

## üöÄ Pr√≥ximos Passos

1. **Aprovar plano** e definir prioridades
2. **Criar branch** `feature/performance-optimization`
3. **Implementar Fase 1** (quick wins)
4. **Medir resultados** e ajustar plano
5. **Prosseguir com Fases 2 e 3**

---

## üìù Notas Adicionais

- Todas as otimiza√ß√µes devem ser testadas em ambiente de desenvolvimento
- Manter compatibilidade com c√≥digo existente
- Documentar mudan√ßas significativas
- Considerar rollback plan para cada fase

**√öltima atualiza√ß√£o**: 18/06/2025